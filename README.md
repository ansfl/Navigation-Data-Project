# Introduction

This repository describes and presented the datasets associated with our paper "The Autonomous Platform Inertial Dataset".\
Paper: Available soon.\
Datasets: Available soon. \
Video: Available soon\

# The Autonomous Platform Inertial Dataset
One of the critical tasks required for fully autonomous functionality is the ability to achieve
an accurate navigation solution; that is, to determine the platform position, velocity, and orientation.
Various sensors, depending on the vehicle environment (air, sea, or land), are employed to achieve this
goal. In parallel to the development of novel navigation and sensor fusion algorithms, machine-learning
based algorithms are penetrating into the navigation and sensor fusion fields. An excellent example for
this trend is pedestrian dead reckoning, used for indoor navigation, where both classical and machine
learning approaches are used to improve the navigation accuracy. To facilitate machine learning algorithmsâ€™
derivation and validation for autonomous platforms, a huge quantity of recorded sensor data is needed.
Unfortunately, in many situations, such datasets are not easy to collect or are not publicly available. To
advance the development of accurate autonomous navigation, this paper presents the autonomous platforms
inertial dataset. It contains inertial sensor raw data and corresponding ground truth trajectories. The dataset
was collected using a variety of platforms including a quadrotor, two autonomous underwater vehicles,
a land vehicle, a remote controlled electric car, and a boat. A total of 805.5 minutes of recordings were
made using different types of inertial sensors, global navigation satellite system receivers, and Doppler
velocity logs. After describing the sensors that were employed for the recordings, a detailed description of
the conducted experiments is provided.

![plot](./images/ship3.JPG)

# A Summarizing table of the recordings
![plot](./images/table.JPG)

