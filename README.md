# Navigation-Data-Project
Navigation Data Project
One of the critical tasks required for fully autonomous functionality is the ability to achieve an accurate navigation solution; that is, to determine the platform position, velocity, and orientation. Various sensors, depending on the vehicle environment (air, sea, or land), are employed to achieve this goal. In parallel to the development of novel navigation and sensor fusion algorithms, machine-learning based algorithms are penetrating into the navigation and sensor fusion fields.  An excellent example  for this trend  is pedestrian dead reckoning, used for indoor navigation, where both classical and machine learning approaches are used to improve the navigation accuracy. To facilitate machine learning algorithms' derivation and validation for autonomous platforms, a huge quantity of recorded sensor data is needed. Unfortunately, in many situations, such datasets are not easy to collect or are not publicly available. 
To advance the development of accurate autonomous navigation, this paper presents the autonomous platforms  inertial dataset. It contains inertial sensor raw data and corresponding ground truth trajectories. The dataset was collected using a variety of platforms including a quadrotor, two autonomous underwater vehicles, a land vehicle, a remote controlled electric car, and a boat. A total of 805.5 minutes of recordings were made using different types of inertial sensors, global navigation satellite system receivers, and Doppler velocity logs.  After describing the sensors that were employed for the recordings, a detailed description of the conducted experiments is provided. The autonomous platform inertial dataset is available at https://drive.google.com/drive/folders/1sbuDlklDdCfcQ0Y6brWcfGyv2iaIlCSU?usp=sharing.
